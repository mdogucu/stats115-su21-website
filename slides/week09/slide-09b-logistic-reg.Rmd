---
title: "Logistic Regression"
author: "Dr. Mine Dogucu"
output: 
  xaringan::moon_reader:
    css: ["slide-style.css"]
    seal: false
    nature:
      ratio: 16:9
      highlightStyle: "pygments"
      highlightLines: true
      highlightLanguage: "r"
---

class: title-slide

```{r child = "../setup.Rmd"}
```

```{r echo=FALSE, message=FALSE}
library(bayesrules)
library(tidyverse)
library(rstanarm)
library(bayesplot)
library(janitor)
library(rstan)
```

<br>
<br>
.right-panel[ 

# `r rmarkdown::metadata$title`
## `r rmarkdown::metadata$author`
Examples from [bayesrulesbook.com](https://bayesrulesbook.com)

]


---

class: middle

$$Y = \begin{cases}
\text{ Yes rain} & \\
\text{ No rain} & \\
\end{cases} \;$$

--

$$\begin{split}
X_1 & = \text{ today's humidity at 9am (percent)} \\
\end{split}$$

---


```{r message=FALSE}
library(bayesrules)
library(rstanarm)
library(bayesplot)
library(tidyverse)

data(weather_perth)
weather <- weather_perth %>%
  select(day_of_year, raintomorrow, humidity9am,
         humidity3pm, raintoday)
```

---

```{r}
glimpse(weather)
```

---

class: middle

```{r echo = FALSE, fig.width = 15, fig.height = 6, message=FALSE}
# Check out some relationships
ggplot(weather, aes(x = humidity9am, fill = raintomorrow)) + 
  geom_density(alpha = 0.5)
g2 <- ggplot(weather, aes(x = humidity3pm, fill = raintomorrow)) + 
  geom_density(alpha = 0.5)
g3 <- ggplot(weather, aes(x = raintoday, fill = raintomorrow)) + 
  geom_bar()
g4 <- ggplot(weather, aes(x = humidity9am, y = humidity3pm, color = raintomorrow)) + 
  geom_point()
```

---

## Odds and Probability

$$\text{odds} = \frac{\pi}{1-\pi}$$
--

if prob of rain = $\frac{2}{3}$ then $\text{odds of rain } = \frac{2/3}{1-2/3} = 2$

--

if prob of rain = $\frac{1}{3}$ then $\text{odds of rain } = \frac{1/3}{1-1/3} = \frac{1}{2}$

--

if prob of rain = $\frac{1}{2}$ then  $\text{odds of rain } = \frac{1/2}{1-1/2} = 1$

---

### Logistic regression model 

likelihood: $Y_i | \pi_i \sim \text{Bern}(\pi_i)$

--

$E(Y_i|\pi_i) = \pi_i$

--

link function: $g(\pi_i) = \beta_0 + \beta_1 X_{i1}$

--

logit link function: $Y_i|\beta_0,\beta_1 \stackrel{ind}{\sim} \text{Bern}(\pi_i) \;\; \text{ with } \;\; \log\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1 X_{i1}$

--

$$\frac{\pi_i}{1-\pi_i} = e^{\beta_0 + \beta_1 X_{i1}}
\;\;\;\; \text{ and } \;\;\;\;
\pi_i = \frac{e^{\beta_0 + \beta_1 X_{i1}}}{1 + e^{\beta_0 + \beta_1 X_{i1}}}$$

---

class: middle

### Bayesian logistic regression model


$\text{likelihood model:} \; \; \; Y_i | \beta_0, \beta_1 \;\;\;\stackrel{ind}{\sim} \text{Bern}(\pi_i)\text{ with } log(\frac{\pi_i}{1-\pi_i}) = \beta_0 + \beta_1X_{i1}$

$\text{prior models:}$ 

$\beta_0\sim N(m_0, s_0 )$  
$\beta_1\sim N(m_1, s_1 )$  

---

$$\log(\text{odds}) = \log\left(\frac{\pi}{1-\pi}\right) = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p \; . $$

When $(X_1,X_2,\ldots,X_p)$ are all 0, $\beta_0$ is the __typical log odds__ of the event of interest and $e^{\beta_0}$ is the __typical odds__.

When controlling for the other predictors $(X_2,\ldots,X_p)$, let $\text{odds}_x$ represent the typical odds of the event of interest when $X_1 = x$ and $\text{odds}_{x+1}$ the typical odds when $X_1 = x + 1$. Then when $X_1$ increases by 1, from $x$ to $x + 1$, $\beta_1$ is the typical __change in log odds__ and $e^{\beta_1}$ is the typical __multiplicative change in odds__:

$$\beta_1 = \log(\text{odds}_{x+1}) - \log(\text{odds}_x)
\;\;\; \text{ and } \;\;\; e^{\beta_1} = \frac{\text{odds}_{x+1}}{\text{odds}_x}$$


---

```{r eval = FALSE}
# Convert raintomorrow to 1s and 0s
weather <- weather %>% 
  mutate(raintomorrow = as.numeric(raintomorrow == "Yes"))

# Simulate the model
rain_model_1 <- stan_glm(raintomorrow ~ humidity9am,
                         data = weather,
                         family = binomial,
                         chains = 4, 
                         iter = 5000*2, 
                         seed = 84735)
```

```{r echo = FALSE, cache=TRUE}
# Convert raintomorrow to 1s and 0s
weather <- weather %>% 
  mutate(raintomorrow = as.numeric(raintomorrow == "Yes"))

# Simulate the model
rain_model_1 <- stan_glm(
  raintomorrow ~ humidity9am, data = weather,
  family = binomial,
  chains = 4, iter = 5000*2, refresh = 0, seed = 84735)
```

---

```{r}
prior_summary(rain_model_1)
```


---

```{r fig.width=10}
mcmc_dens_overlay(rain_model_1)
```

---

```{r}
rain_model_1_df <- as.data.frame(rain_model_1)
head(rain_model_1_df, 3)
```

---

class: middle

$$\pi = \frac{e^{\beta_0 + \beta_1 X_1}}{1 + e^{\beta_0 + \beta_1 X_1}}$$
---

```{r eval=FALSE}
# The first 50 posterior parameter sets
first_50 <- head(rain_model_1_df, 50)

# Function that calculates model trend on probability scale
prob_trend <- function(beta0, beta1, x){
  exp(beta0 + beta1*x) / (1 + exp(beta0 + beta1*x))}

# Plot the first 50 posterior model trends
ggplot(weather, aes(x = humidity9am, y = raintomorrow)) + 
  mapply(function(beta0, beta1) {
    stat_function(fun = prob_trend,
      args = list(beta0 = beta0, beta1 = beta1), size = 0.1)
    },
    beta0 = first_50$`(Intercept)`, beta1 = first_50$humidity9am
  ) + 
  labs(y = "probability of rain")
```

---

```{r echo=FALSE}
# The first 50 posterior parameter sets
first_50 <- head(rain_model_1_df, 50)

# Function that calculates model trend on probability scale
prob_trend <- function(beta0, beta1, x){
  exp(beta0 + beta1*x) / (1 + exp(beta0 + beta1*x))}

# Plot the first 50 posterior model trends
ggplot(weather, aes(x = humidity9am, y = raintomorrow)) + 
  mapply(function(beta0, beta1) {
    stat_function(fun = prob_trend,
      args = list(beta0 = beta0, beta1 = beta1), size = 0.1)
    },
    beta0 = first_50$`(Intercept)`, beta1 = first_50$humidity9am
  ) + 
  labs(y = "probability of rain")
```

---

class: middle

### Prediction and Classification

\begin{equation}
\log\left( \frac{\pi}{1-\pi}\right) = \beta_0 + \beta_1 * 99 
\;\;\;\; \text{ and } \;\;\;\;
\pi = \frac{e^{\beta_0 + \beta_1 * 99}}{1 + e^{\beta_0 + \beta_1 * 99}} \; .
\end{equation}

---

```{r}
# Posterior predictions on log(odds) scale
logodds_prediction <- posterior_linpred(
  rain_model_1, newdata = data.frame(humidity9am = 99))

head(logodds_prediction,3)

```


---

```{r}
# Posterior predictions on probability scale
prob_prediction <- posterior_epred(
  rain_model_1, newdata = data.frame(humidity9am = 99))

head(prob_prediction,3)
```

---


```{r}
# Posterior predictions of binary outcome
set.seed(84735)
binary_prediction <- posterior_predict(
  rain_model_1, newdata = data.frame(humidity9am = 99))

head(binary_prediction,3)

```

---

```{r}
rain_model_1_df %>% 
  mutate(log_odds = c(logodds_prediction), 
    prob = c(prob_prediction), Y = c(binary_prediction)) %>% 
  head(3)
```

```{r echo = FALSE}
rain_sum <- rain_model_1_df %>% 
  mutate(log_odds = c(logodds_prediction), 
    prob = c(prob_prediction), Y = c(binary_prediction))
b0 <- round(rain_sum[1,1],3)
b1 <- round(rain_sum[1,2],3)
log_pred  <- round(b0 + b1 * 99,4)
prob_pred <- round(exp(log_pred) / (1 + exp(log_pred)),2)
```

$\beta_0 = `r b0`$ and $\beta_1 = `r b1`$

--

$\log( \frac{\pi}{1-\pi}) = `r b0` + `r b1` * 99 = `r log_pred`$

$\pi  = \frac{e^{`r b0` + `r b1` * 99}}{1 + e^{`r b0` + `r b1` * 99}} = `r prob_pred`$ and $Y$ is a random draw from Bern(0.52)

---

```{r eval = FALSE}
mcmc_dens(logodds_prediction) + labs(x = "log(odds)")
mcmc_dens(prob_prediction) + labs(x = "probability")
mcmc_hist(binary_prediction) + labs(x = "Y")
```

```{r echo = FALSE, fig.width = 6, message=5, fig.width=10, fig.height=5}
g1 <- mcmc_dens(logodds_prediction) + labs(x = "log(odds)")
g2 <- mcmc_dens(prob_prediction) + labs(x = "probability")
g3 <- mcmc_hist(binary_prediction) + labs(x = "Y")
gridExtra::grid.arrange(g1,g2,g3,ncol=3)
```

---
class: middle

```{r}
table(binary_prediction)
colMeans(binary_prediction)
```

---

class: middle

## Classification rule

- If $p \ge c$, then classify $Y$ as 1.
- If $p < c$, then classify $Y$ as 0.

---

```{r}
set.seed(84735)
rain_pred_1 <- posterior_predict(rain_model_1, 
                                 newdata = weather)
head(rain_pred_1, 3)
```

---

```{r}
weather_classifications <- weather %>%
  mutate(rain_prop = colMeans(rain_pred_1)) %>%
  mutate(rain_class_1 = as.numeric(rain_prop >= 0.5)) %>%
  select(humidity9am, rain_prop, rain_class_1, raintomorrow)
```

---

```{r}
head(weather_classifications,3)
```


---

class: middle

### Confusion Matrix

```{r}
tabyl(weather_classifications,
      raintomorrow, rain_class_1)
```

---

```{r}
set.seed(84735)
classification_summary(model = rain_model_1, 
                       data = weather,
                       cutoff = 0.5)
```

---

__Sensitivity, specificity, and overall accuracy__

A confusion matrix summarizes the results of these classifications relative to the actual observations where $a + b + c + d = n$:

<div align="center">


|         | $\hat{Y} = 0$ | $\hat{Y} = 1$ |
|---------|---------------|---------------|
| $Y = 0$ | $a$           | $b$           |
| $Y = 1$ | $c$           | $d$           |


 

$$\text{overall accuracy} = \frac{a + d}{a + b + c + d}$$    

$$\text{sensitivity} = \frac{d}{c + d}
\;\;\;\; \text{ and } \;\;\;\;
\text{specificity} = \frac{a}{a + b}$$    