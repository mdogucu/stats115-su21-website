---
title: "Posterior Inference"
author: "Dr. Mine Dogucu"
output: 
  xaringan::moon_reader:
    css: ["slide-style.css"]
    seal: false
    nature:
      ratio: 16:9
      highlightStyle: "pygments"
      highlightLines: true
      highlightLanguage: "r"
---

class: title-slide

```{r child = "../setup.Rmd"}
```

```{r echo=FALSE, message=FALSE}
library(bayesrules)
library(tidyverse)
library(janitor)
library(ggforce)
library(gridExtra)
```

<br>
<br>
.right-panel[ 

# `r rmarkdown::metadata$title`
## `r rmarkdown::metadata$author`
Examples from [bayesrulesbook.com](https://bayesrulesbook.com)

]

---

```{r}
library(bayesrules)
data(moma_sample)
glimpse(moma_sample)
```

---

class: middle

$$Y|\pi  \sim \text{Bin}(100, \pi)$$ 

$$\pi  \sim \text{Beta}(4, 6)$$

---

```{r}
moma_sample %>% 
  mutate(genx = (birth >= 1965)) %>% 
  tabyl(genx)
```

---

class: middle

$$\begin{split}
Y | \pi & \sim \text{Bin}(100, \pi) \\
\pi & \sim \text{Beta}(4, 6) \\
\end{split} \;\;\;\; \Rightarrow \;\;\;\; \pi | (Y = 14) \sim \text{Beta}(18, 92)$$

---

```{r fig.height=5, fig.width=9}
plot_beta_binomial(alpha = 4, beta = 6, y = 14, n = 100)
```

---

```{r echo=FALSE, fig.width=12}
# Keep: these references are woven throughout the discussion

# Data
y <- 14
n <- 100

# Prior parameters
prior_a <- 4
prior_b <- 6

# Posterior parameters
post_a <- prior_a + y
post_b <- prior_b + n - y

# Posterior trend
post_mean_unrounded <- round(post_a / (post_a + post_b),3)
post_mean <- round(post_mean_unrounded, 2)
post_mode <- round((post_a - 1) / (post_a + post_b - 2), 2)

# 95% CI
qs <- qbeta(c(0.025, 0.975), post_a, post_b)
lower_95 <- round(qs[1],2)
upper_95 <- round(qs[2],2)

# 99% CI
qs <- qbeta(c(0.005, 0.995), post_a, post_b)
lower_99 <- round(qs[1],2)
upper_99 <- round(qs[2],2)

# Probabilities
post_prob <- pbeta(0.20, post_a, post_b)
prior_prob <- pbeta(0.20, prior_a, prior_b)
new_y <- 0
new_n <- 10
new_post_a <- prior_a + new_y
new_post_b <- prior_b + new_n - new_y
qs <- qbeta(c(0.025, 0.975), new_post_a, new_post_b)
new_lower_95 <- round(qs[1],2)
new_upper_95 <- round(qs[2],2)

plot_fun <- function(a,b,x,n,level){
  q1  <- (1 - level)/2
  q2  <- 1 - q1
  p_a <- a + x
  p_b <- b + n - x
  ci  <- qbeta(c(q1,q2), p_a, p_b)
  post_mode <- (p_a - 1) / (p_a + p_b - 2)
  marks <- c(ci, post_mode)
  ggplot(data.frame(x = c(0.4,1)), aes(x=x)) + 
    stat_function(fun = dbeta, args = list(p_a, p_b), xlim = ci, geom = "area", fill = "lightblue") + 
    stat_function(fun = dbeta, args = list(p_a, p_b)) + 
    geom_segment(data = data.frame(x = marks, y1 = c(0,0,0), y2 = dbeta(marks, p_a, p_b)),
                 aes(x = x, xend = x, y = y1, yend = y2)) +
    labs(x = expression(pi), y = "density") + 
    lims(y = c(0,12), x = c(0,0.6))
}

plot_fun(4, 4, y, n, level = 0.95) +
  labs(y = expression(paste("f(",pi,"|Y=14)")))
```

---

class: middle

```{r}
summarize_beta_binomial(4, 6, y = 14, n = 100)
```

---

class: middle

## 95% Posterior Credible Interval (CI)

0.025th & 0.975th quantiles of the Beta(18,92) posterior

```{r}
qbeta(c(0.025, 0.975), 18, 92)
```

--

$\int_{0.1}^{0.24} f(\pi|(y=14)) d\pi  \; \approx \; 0.95$

---

```{r post-ci-ch8, fig.width = 10, echo = FALSE, message=FALSE}
# Alt text: The same roughly symmetric density curve, which ranges from roughly 0.05 to 0.3 is plotted three times. In the left curve, a narrow area between 0.14 and 0.19 is shaded in. In the middle curve, a wider area between 0.1 and 0.24 is shaded in. In the right curve, the widest area between 0.08 and 0.26 is shaded in.
g1 <- plot_fun(prior_a, prior_b, y, n, level = 0.50) + lims(x = c(0,0.32)) +
  labs(title = "50% posterior CI")
g2 <- plot_fun(prior_a, prior_b, y, n, level = 0.95) + lims(x = c(0,0.32)) +
  labs(title = "95% posterior CI")
g3 <- plot_fun(prior_a, prior_b, y, n, level = 0.99) + lims(x = c(0,0.32)) +
  labs(title = "99% posterior CI")
grid.arrange(g1,g2,g3,ncol=3)
```

---

class: middle 

$$\begin{split}
H_0: & \; \; \pi \ge 0.20 \\
H_a: & \; \; \pi < 0.20 \\
\end{split}$$

---


```{r post-prob-ch8, echo = FALSE}
plot_prob_plot <- function(a,b,cutoff){
  ggplot(data.frame(x = c(0,1)), aes(x=x)) + 
    stat_function(fun = dbeta, args = list(a, b), xlim = c(0,cutoff), geom = "area", fill = "lightblue") + 
    stat_function(fun = dbeta, args = list(a, b)) + 
    geom_segment(aes(x = cutoff, xend = cutoff, y = 0, yend = dbeta(cutoff, a, b))) +
    labs(x = expression(pi), y = "density")
}

plot_prob_plot(post_a, post_b, cutoff = 0.20) + 
  lims(y = c(0,12.5), x = c(0, 0.32))
```

---

```{r}
# Posterior probability that pi < 0.20
post_prob <- pbeta(0.20, 18, 92)
post_prob
```

---

$$\text{Posterior odds } = \frac{P(H_a \; | \; (Y=14))}{P(H_0 \; | \; (Y=14))} \approx 5.62 $$  

--

```{r}
# Posterior odds
post_odds <- post_prob / (1 - post_prob)
post_odds
```

---

```{r prior-post-ch8, echo = FALSE, fig.width = 10}
g1 <-plot_prob_plot(prior_a, prior_b, cutoff = 0.20) + 
  lims(y = c(0,12.5)) + 
  labs(title = "Prior")

g2 <- plot_prob_plot(post_a, post_b, cutoff = 0.20) + 
  lims(y = c(0,12.5)) + 
  labs(title = "Posterior")

grid.arrange(g1, g2, ncol = 2)

```

---

$$P(\pi<0.20)$$
```{r}
prior_prob <- pbeta(0.20, 4, 6)
prior_prob
```

--

$$\text{Prior odds } = \frac{P(H_a)}{P(H_0)} \approx 0.093 \; .$$ 

```{r}
prior_odds <- prior_prob / (1 - prior_prob)
prior_odds
```

---

The __Bayes Factor (BF)__ compares the posterior odds to the prior odds, hence provides insight into just how much our understanding about Gen X representation _evolved_ upon observing our sample data:


$$\text{Bayes Factor} = \frac{\text{Posterior odds }}{\text{Prior odds }}$$

```{r echo = FALSE}
BF <- post_odds / prior_odds
```

---

## Bayes Factor

In a hypothesis test of two competing hypotheses, $H_a$ vs $H_0$, the Bayes Factor is an odds ratio for $H_a$:

$$\text{Bayes Factor}
= \frac{\text{Posterior odds}}{\text{Prior odds}}
= \frac{P(H_a | Y) / P(H_0 | Y)}{P(H_a) / P(H_0)}
 \; .$$

As a ratio, it's meaningful to compare the Bayes Factor (BF)\ to 1.  To this end, consider three possible scenarios:

1. BF = 1:  The plausibility of $H_a$ _didn't change_ in light of the observed data.
2. BF > 1:  The plausibility of $H_a$ _increased_ in light of the observed data.  Thus the greater the Bayes Factor, the more convincing the evidence for $H_a$.
3. BF < 1:  The plausibility of $H_a$ _decreased_ in light of the observed data. 

---

## Two-sided Tests

$$\begin{split}
H_0: & \; \; \pi = 0.3 \\
H_a: & \; \; \pi \ne 0.3 \\
\end{split}$$

$$\text{Posterior odds } = \frac{P(H_a \; | \; (Y=14))}{P(H_0 \; | \; (Y=14))} = \frac{1}{0} = \text{ nooooo!}$$

--

Recall 95% posterior CI

```{r}
qbeta(c(0.025, 0.975), 18, 92)
```

---

```{r cache=TRUE, message=FALSE}
library(rstan)
# STEP 1: DEFINE the model
art_model <- "
  data {
    int<lower=0, upper=100> Y;
  }
  parameters {
    real<lower=0, upper=1> pi;
  }
  model {
    Y ~ binomial(100, pi);
    pi ~ beta(4, 6);
  }
"
# STEP 2: SIMULATE the posterior
art_sim <- stan(model_code = art_model, data = list(Y = 14), 
  chains = 4, iter = 5000*2, seed = 84735)
```

---

```{r message=FALSE, fig.height=5}
library(bayesplot)
# Parallel trace plots & density plots
mcmc_trace(art_sim, pars = "pi", size = 0.5)
```

---

```{r message=FALSE}
# Combined density plot
mcmc_dens_overlay(art_sim, pars = "pi")
```

---

```{r message=FALSE}
# Combined density plot
mcmc_dens(art_sim, pars = "pi")
```

---

```{r}
broom.mixed::tidy(art_sim, conf.int = TRUE, conf.level = 0.95)
```


```{r eval=FALSE}
summary(art_sim, pars = "pi")$summary
```

---

```{r}
mcmc_areas(art_sim, pars = "pi",
  prob = 0.95, point_est = "mean")
```

---

```{r}
mcmc_areas(art_sim, pars = "pi",
  prob = 0.95, point_est = "mean")
```

---

```{r}
art_chains_df <- as.data.frame(art_sim, 
  pars ="lp__", include = FALSE)

art_chains_df %>% 
  summarize(post_mean = mean(pi), 
    post_mode = sample_mode(pi),
    lower_95 = quantile(pi, 0.025),
    upper_95 = quantile(pi, 0.975))
```

---


```{r}
art_chains_df %>% 
  mutate(exceeds = pi < 0.20) %>% 
  tabyl(exceeds)
```

--

```{r}
post_prob
```

---

class: middle

__a Bayesian analysis assesses the uncertainty regarding an unknown parameter $\pi$ in light of observed data $Y$__.


$$P((\pi < 0.20) \; | \; (Y = 14)) = `r post_prob` \;.$$

--

__a frequentist analysis assesses the uncertainty of the observed data $Y$ in light of assumed values of $\pi$.__

$$P((Y \le 14) | (\pi = 0.20)) = 0.08$$
